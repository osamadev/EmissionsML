{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "## Step 2: Models Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "### Step 2.1: XGBoost MultiOutputRegressor Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# drop columns that are not selected and the target columns\n",
    "y = final_merged_df[['co2_avg', 'pm10_avg', 'pm25_avg', 'no2_avg']]\n",
    "X = final_merged_df.drop(columns=['co2_avg', 'pm10_avg', 'pm25_avg', 'no2_avg'])\n",
    "\n",
    "# drop aadt columns and keep vkm columns as they are highly correlated. vkm is calculated using aadt and speed columns\n",
    "X.drop(columns=['aadt_motorcycle', 'aadt_taxi',\n",
    "       'aadt_petrol_car', 'aadt_diesel_car', 'aadt_electric_car',\n",
    "       'aadt_petrol_phv', 'aadt_diesel_phv', 'aadt_electric_phv',\n",
    "       'aadt_petrol_lgv', 'aadt_diesel_lgv', 'aadt_electric_lgv',\n",
    "       'aadt_hgvs_rigid_2_axles', 'aadt_hgvs_rigid_3_axles',\n",
    "       'aadt_hgvs_rigid_4_or_more_axles', 'aadt_hgvs_articulated_3_to_4_axles',\n",
    "       'aadt_hgvs_articulated_5_axles', 'aadt_hgvs_articulated_6_axles',\n",
    "       'aadt_buses', 'aadt_coaches'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save features list in a csv file\n",
    "X.to_csv('df_final_features_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# final list of features used for training\n",
    "selected_columns = X.columns\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# implement multi-output regression using xgboost regressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the model\n",
    "xgb = MultiOutputRegressor(XGBRegressor(objective='reg:squarederror', n_estimators=1000, \n",
    "                                        learning_rate=0.1, max_depth=6, random_state=42))\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# predict the target values\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(xgb, 'xgb_model.pkl')\n",
    "\n",
    "# load the model\n",
    "xgb = joblib.load('xgb_model.pkl')\n",
    "\n",
    "# predict the emissions for a new data\n",
    "new_data = X_test.iloc[0]\n",
    "new_data = new_data.values.reshape(1, -1)\n",
    "y_pred = xgb.predict(new_data)\n",
    "print(y_pred)\n",
    "\n",
    "# compare the predicted values with the actual values\n",
    "print(y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# display the predicted values and actual values in a dataframe\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['co2_avg', 'pm10_avg', 'pm25_avg', 'no2_avg'])\n",
    "y_test_df = y_test.reset_index(drop=True)\n",
    "y_test_df = y_test_df.iloc[0].to_frame().T\n",
    "y_test_df.columns = ['co2_avg', 'pm10_avg', 'pm25_avg', 'no2_avg']\n",
    "\n",
    "# rename the columns to have 'actual' and 'predicted' as a prefix\n",
    "y_pred_df = y_pred_df.add_prefix('predicted_')\n",
    "y_test_df = y_test_df.add_prefix('actual_')\n",
    "\n",
    "# concatenate the two dataframes\n",
    "df_compare = pd.concat([y_test_df, y_pred_df], axis=1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance from RF model (sum importance across both targets)\n",
    "\n",
    "# Extract feature importances for each target variable\n",
    "feature_importances = np.mean([est.feature_importances_ for est in xgb.estimators_], axis=0)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(feature_names, feature_importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance in Key Pollutant Average Emission Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "### Step 2.2: Random Forest Multioutput Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 'co2_avg', 'pm10_avg', 'pm25_avg', 'no2_avg'\n",
    "# Evaluate performance\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf, multioutput='raw_values')\n",
    "r2_rf = r2_score(y_test, y_pred_rf, multioutput='raw_values')\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf, multioutput='raw_values')\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Random Forest - MAE: {mae_rf}\")\n",
    "print(f\"Random Forest - R² Score: {r2_rf}\")\n",
    "print(f\"Random Forest - MSE: {mse_rf}\")\n",
    "print(f\"Random Forest - RMSE: {rmse_rf}\")\n",
    "\n",
    "print(f\"Random Forest - MSE: {mse}\")\n",
    "print(f\"Random Forest - RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "1. Mean Absolute Error (MAE)\n",
    "\n",
    "MAE:\n",
    "[0.9121,0.0002,0.0001,0.0021]\n",
    "\n",
    "    MAE measures the average absolute difference between actual and predicted values.\n",
    "    Lower MAE values indicate better performance.\n",
    "    The first target variable (co2_avg) has an MAE of 0.9121, meaning on average, the prediction error is around 0.91 units.\n",
    "    The other target variables ('pm10_avg', 'pm25_avg', 'no2_avg') have very small MAE values, suggesting the model predicts them with high accuracy.\n",
    "\n",
    "2. R² Score (Coefficient of Determination)\n",
    "\n",
    "R² Scores:\n",
    "[0.9860,0.9004,0.9446,0.9829]\n",
    "\n",
    "    R² measures how well the model explains variance in the data.\n",
    "    The closer R² is to 1, the better the model performance.\n",
    "    co2_avg (first value: 0.9860): The model explains 98.4% of the variance in PM2.5 values.\n",
    "    pm10_avg (second value: 0.9004): The model explains 90% of the variance in pm10_avg.\n",
    "    The last two values ('pm25_avg', 'no2_avg') have slightly lower but still strong performance (0.9446 and 0.9829).\n",
    "        0.90 indicates that 90% of the variance is explained by the model, which is good performance.\n",
    "\n",
    "3. Mean Squared Error (MSE)\n",
    "\n",
    "MSE:\n",
    "[17.8751,0.000002,0.0000005,0.0001]\n",
    "\n",
    "    MSE penalises larger errors more heavily than MAE since it squares the errors.\n",
    "    Lower values mean better predictions.\n",
    "    The first value (17.8751) is for co2_avg, suggesting some variation in predictions but still reasonably low.\n",
    "    The other values are extremely small, indicating high precision for 'pm10_avg', 'pm25_avg', 'no2_avg'.\n",
    "\n",
    "\n",
    "4. Root Mean Squared Error (RMSE)\n",
    "\n",
    "RMSE:\n",
    "[4.2279,0.0017,0.0007,0.0095]\n",
    "\n",
    "    RMSE is the square root of MSE and gives an error measure in the same units as the data.\n",
    "    The first value (4.2279) means that CO2 predictions have an average error of about 4.5 units.\n",
    "    The other RMSE values are extremely small, indicating highly accurate predictions for SO₂ and other pollutants.\n",
    "\n",
    "\n",
    "Overall Interpretation:\n",
    "\n",
    "✅ Good performance\n",
    "\n",
    "    R² values close to 1 suggest that the model explains almost all variance in the data.\n",
    "    Low MAE and RMSE values indicate that the model makes highly accurate predictions.\n",
    "    Small MSE for 'pm10_avg', 'pm25_avg', 'no2_avg' means the model is extremely precise for those variables.\n",
    "\n",
    "⚠️ Potential areas for improvement:\n",
    "\n",
    "    The first variable (co2_avg) has slightly higher RMSE (4.2279) than others. We also need to make sure that the other values are not subjects to overfitting. We could try to enhance this models by applying methods such as Hyperparameter tuning (adjust n_estimators, max_depth, etc.) or Feature engineering (adding more relevant input variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance from RF model (sum importance across both targets)\n",
    "\n",
    "# Extract feature importances for each target variable\n",
    "feature_importances = np.mean([est.feature_importances_ for est in rf.estimators_], axis=0)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(feature_names, feature_importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance in Key Pollutant Average Emission Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "### Step 2.3: Ridge Multi-Output Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load the merged dataframe from the csv file\n",
    "final_merged_df = pd.read_csv('final_merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load the final list of features from the csv file\n",
    "final_features_df = pd.read_csv('df_final_features_list.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Merged Data:\\n\", final_merged_df.head())\n",
    "print(\"\\nFinal Features List:\\n\", final_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Column Names in final_merged_df:\")\n",
    "print(final_merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# final list of features used for training\n",
    "selected_columns = final_features_df.columns.tolist()\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure only selected features are used\n",
    "X = final_merged_df[selected_columns]\n",
    "\n",
    "# Define target variables\n",
    "target_variables = ['co2_avg', 'pm10_avg', 'pm25_avg', 'no2_avg']\n",
    "\n",
    "\n",
    "# Define target matrix (multi-output regression)\n",
    "y = final_merged_df[target_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Save the trained model\n",
    "model_filename = \"ridge_model_all_emissions.pkl\"\n",
    "joblib.dump((ridge, scaler, target_variables), model_filename)\n",
    "print(f\"Model saved: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_ridge, loaded_scaler, loaded_targets = joblib.load(model_filename)\n",
    "print(f\"\\n Loaded model for targets: {loaded_targets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Transform test data using saved scaler\n",
    "X_test_scaled = loaded_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Predict emissions for each target variable\n",
    "y_pred = loaded_ridge.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert predictions to DataFrame for evaluation\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=loaded_targets, index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for target in loaded_targets:\n",
    "    mse = mean_squared_error(y_test[target], y_pred_df[target])\n",
    "    r2 = r2_score(y_test[target], y_pred_df[target])\n",
    "\n",
    "    print(f\"\\nResults for {target}:\")\n",
    "    print(f\"  - Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"  - R² Score: {r2}\")\n",
    "\n",
    "    # Store results\n",
    "    results[target] = {\"MSE\": mse, \"R2\": r2}\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_test[target], y=y_pred_df[target], alpha=0.5)\n",
    "    plt.xlabel(f\"Actual {target}\")\n",
    "    plt.ylabel(f\"Predicted {target}\")\n",
    "    plt.title(f\"Ridge Regression Predictions vs Actual ({target})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n Final Model Performance Summary:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract feature importance from trained Ridge model\n",
    "feature_importance = pd.DataFrame(loaded_ridge.coef_, columns=X.columns, index=loaded_targets)\n",
    "\n",
    "# Plot feature importance for each emission type\n",
    "for target in loaded_targets:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sorted_coeffs = feature_importance.loc[target].sort_values(ascending=False)\n",
    "    sorted_coeffs.plot(kind=\"bar\", color=\"royalblue\")\n",
    "    plt.title(f\"Feature Importance for {target}\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Coefficient Value\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid for alpha tuning\n",
    "param_grid = {\"alpha\": [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "ridge_cv = GridSearchCV(Ridge(), param_grid, scoring=\"r2\", cv=5)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_alpha = ridge_cv.best_params_[\"alpha\"]\n",
    "print(f\"Best Alpha Value: {best_alpha}\")\n",
    "\n",
    "# Train Ridge Regression using the optimized alpha\n",
    "optimized_ridge = Ridge(alpha=best_alpha)\n",
    "optimized_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the optimized model\n",
    "joblib.dump((optimized_ridge, scaler, target_variables), \"optimized_ridge_model.pkl\")\n",
    "print(\"Optimized Ridge model saved.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
